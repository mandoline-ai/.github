# Mandoline

[Mandoline](https://mandoline.ai) helps developers evaluate and improve LLM applications in ways that matter to users.

Create custom metrics that align with your specific use case, evaluate LLM performance in real situations, and track improvements over time.

## Documentation

- [Getting Started](https://mandoline.ai/docs/getting-started-with-mandoline)
- [Core Concepts](https://mandoline.ai/docs/mandoline-core-concepts)
- [API Reference](https://mandoline.ai/docs/mandoline-api-reference)

## Tutorials

- [Prompt Engineering: Reduce Unwanted LLM Behaviors](https://mandoline.ai/docs/tutorials/prompt-engineering-reduce-unwanted-llm-behaviors)
- [Model Selection: Compare LLMs for Creative Tasks](https://mandoline.ai/docs/tutorials/model-selection-compare-llms-for-creative-tasks)

## Analysis & Insights

- [Comparing Refusal Behavior Across Top Language Models](https://mandoline.ai/blog/comparing-llm-refusal-behavior)

## SDKs

- [Node.js](https://github.com/mandoline-ai/mandoline-node)
- [Python](https://github.com/mandoline-ai/mandoline-python)

## Support

- [GitHub Issues](https://github.com/mandoline-ai/mandoline-node/issues)
- [Email](mailto:support@mandoline.ai)
